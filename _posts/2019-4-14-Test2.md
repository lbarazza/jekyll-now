---
layout: post
title: test n. 2
---

This is just an experiment.
Tradizione di ricerca
Molteplici furono i passi che portarono alla nascita di questa disciplina. Il primo, sia a livello di importanza che di ordine cronologico, è l’avvento dei calcolatori ed il continuo interesse rivolto ad essi. Già nel 1623, grazie a Willhelm Sickhart, si arrivò a creare macchine in grado di effettuare calcoli matematici con numeri fino a sei cifre, anche se non in maniera autonoma. Nel 1642 Blaise Pascal costruì una macchina in grado di fare operazioni utilizzando il riporto automatico, mentre nel 1674 Gottfried Wilhelm von Leibniz creò una macchina in grado di effettuare la somma, la differenza e la moltiplicazione in maniera ricorsiva. Tra il 1834 ed il 1837 Charles Babbage lavorò al modello di una macchina chiamata macchina analitica, le cui caratteristiche anticiparono in parte quelle dei moderni calcolatori. Nel ventesimo secolo l’attenzione sui computer ritornò ad accendersi: nel 1937, ad esempio, Claude Shannon, all’università di Yale, mostrò che l’algebra booleana e le operazioni binarie potessero rappresentare il cambiamento circuitale all’interno dei telefoni.
Un ulteriore passo importante fu l’articolo di Alan Turing redatto nel 1936, On Computable Numbers, With An Application To The Entscheidungsproblem[6], che pone le basi per concetti quali calcolabilità, computabilità, macchina di Turing, definizioni cardine per i calcolatori sino ai giorni nostri. In seguito, nel 1943 McCulloch e Pitts crearono ciò che viene ritenuto il primo lavoro inerente all’intelligenza artificiale[7]. Tale sistema impiega un modello di neuroni artificiali nel quale lo status di tali neuroni può essere “on” o “off,” con un passaggio a “on” in presenza di stimoli causati da un numero sufficiente di neuroni circostanti.
McCulloch e Pitts arrivarono quindi a mostrare, ad esempio, che qualsiasi funzione computabile può essere rappresentata da qualche rete di neuroni, e che tutti i connettivi logici (“and”, “or”, ...) possono essere implementati da una semplice struttura neurale. Sette anni più tardi, nel 1950, due studenti dell’università di Harvard, Marvin Minsky e Dean Edmonds, crearono quella che viene riconosciuta come la prima rete neurale, conosciuta con il nome di SNARC.
La nascita effettiva della disciplina (1956)
Nel 1956, nel New Hampshire, al Dartmouth College, si tenne un convegno al quale presero parte alcune delle figure di spicco del nascente campo della computazione dedicata allo sviluppo di sistemi intelligenti: John McCarthy, Marvin Minsky, Claude Shannon e Nathaniel Rochester. Su iniziativa di McCarthy, un team di dieci persone avrebbe dovuto creare in due mesi una macchina in grado di simulare ogni aspetto dell’apprendimento e dell’intelligenza umana. Ad aderire a tale iniziativa, furono alcuni ricercatori, tra cui anche Trenchard More di Princeton, Arthur Samuel di IBM, e Ray Solomonoff e Oliver Selfridge del MIT. Nello stesso convegno, un’altra iniziativa catalizzò l’attenzione oltre al progetto di McCarthy: il programma di Allen Newell e Herbert Simon. Questi due ricercatori, a differenza di McCarthy, avevano già un programma capace di qualche forma di ragionamento, conosciuto con il nome di Logic Theorist, o LP, in grado di dimostrare teoremi partendo dai principi della matematica. Sempre nello stesso convegno, McCarthy introdusse l’espressione intelligenza artificiale, che segnò, in maniera indelebile, la nascita effettiva di tale disciplina, conferendole una natura propria.

Prime grandi aspettative (1950-1965)
Il programma creato da Newell e Simon permise loro di progredire e creare un programma chiamato General Problem Solver, o GPS. A differenza del LP, il GPS fu ideato con lo scopo di imitare i processi di risoluzione dei problemi utilizzati dagli esseri umani. Nei ristretti casi nel quale il programma poteva operare, si notò che l’approccio con il quale il programma considerava gli obiettivi e le azioni era assimilabile ad uno umano. Negli stessi anni, presso l’IBM, Rochester con dei suoi colleghi cominciò a sviluppare altri programmi capaci di ragionamento.

Nel 1959, Herbert Gelemter creò il Geometry Theorem Prover, un programma in grado di dimostrare teoremi di geometria complessi. L’anno precedente, presso il MIT, McCarthy diede un altro contributo al campo dell’intelligenza artificiale definendo quello che per trent’anni fu riconosciuto come il linguaggio di programmazione dominante per la realizzazione dei sistemi di intelligenza artificiale: il Lisp. Oltre a ciò, McCarthy scrisse un documento intitolato Programs with Common Sense[8], nel quale descrive un programma ideale, chiamato Advice Taker, che può essere visto come il primo sistema intelligente completo. A differenza del LP e del GSP, l’Advice Taker era progettato per trovare soluzioni a problemi di tipo diverso, ovvero non strettamente matematici.

Minsky, durante il suo periodo al MIT, supervisionò la creazione di programmi per affrontare quelli che vengono chiamati micro mondi, ovvero problemi limitati e descritti da asserzioni che richiedevano l’utilizzo di ragionamento per essere risolti. Tra questi, il programma di James Slagle del 1963, SAINT, era in grado di risolvere problemi riguardo al calcolo integrale in forma chiusa, tipici del primo anno del college.

Prime difficoltà (1966-1969)
Tra le varie aspirazioni da parte dei ricercatori vi era principalmente quella di creare macchine in grado di esibire capacità di ragionamento simili a quelle umane. Ad esempio, Herbert Simon, nel 1957, stimò che nel giro di dieci anni ci sarebbero state macchine in grado di competere con i campioni di scacchi (previsione che si avvererà, ma dopo quarant’anni). Queste aspirazioni, però, dovettero scontrarsi con alcune difficoltà: prime fra tutte, l’assoluta mancanza di conoscenza semantica relativa ai domini trattati dalle macchine, in quanto la loro capacità di ragionamento si limitava ad una mera manipolazione sintattica. A causa di questa difficoltà, nel 1966 il governo degli Stati Uniti d’America interruppe i fondi per lo sviluppo delle macchine traduttrici. Un ulteriore problema fu l’impossibilità del trattare molti problemi che l’intelligenza artificiale si era proposta. Questo perché si riteneva che “scalare” le dimensioni di un problema fosse solo una questione di hardware e memoria.

Questo tipo di ottimismo fu presto spento quando i ricercatori fallirono nel dimostrare teoremi a partire da più di una dozzina di assiomi. Si capì quindi che il fatto di disporre di un algoritmo che, a livello teorico, fosse in grado di trovare una soluzione a un problema non significava che un corrispondente programma fosse in grado di calcolarla effettivamente a livello pratico. Un terzo tipo di difficoltà furono le limitazioni alla base della logica, nel senso di ragionamento, dei calcolatori. Nel documento di Minsky e Papert, intitolato Perceptrons (1969), si mostrò che, nonostante un percettrone (una semplice forma di rete neurale) fosse in grado di apprendere qualsiasi funzione potesse rappresentare, un percettrone con due input non era in grado di rappresentare una funzione che riconoscesse quando i due input sono diversi.

Sistemi basati sulla conoscenza (1969-1979)
Le precedenti difficoltà portarono a definire gli approcci adottati dalle macchine come approcci deboli, necessitando quindi di una conoscenza maggiore inerente al campo di applicazione. Nel 1969, grazie a Ed Feigenbaum (studente di Herbert Simon), Bruce Buchanam e Joshua Lederberg, venne creato il programma DENDRAL. Tale programma era in grado, a partire dalle informazioni sulla massa molecolare ricavate da uno spettrometro, di ricostruire la struttura di una molecola. Questo programma fu quindi il primo dei sistemi basati su un uso intensivo della conoscenza, che arrivarono più tardi ad inglobare tutti i concetti teorizzati da McCarthy per l’Advice Taker. Successivamente, Feigenbaum cominciò insieme ad altri ricercatori di Stanford l’Heuristic Program Project (HPP), al fine di estendere gli scenari applicativi di questi sistemi, cominciando con il sistema MYCIN nell’ambito delle diagnosi delle infezioni sanguigne. Si cominciò quindi a teorizzare dei sistemi conosciuti come sistemi esperti, ovvero in grado di possedere una conoscenza esperta in un determinato scenario di applicazione.

Dall’ambiente accademico all’industria (1980-1985)
Il primo sistema di intelligenza artificiale utilizzato in ambito commerciale fu R1, utilizzato dalla Digital Equipment nel 1982. Lo scopo del programma era quello di aiutare a configurare gli ordini per nuovi computer. Nel 1986, fu in grado di far risparmiare alla compagnia 40 milioni di dollari all’anno. Anche la DuPont utilizzò sistemi simili, risparmiando circa dieci milioni di dollari all’anno. Negli anni '80 dello scorso secolo, quasi ogni grande azienda americana aveva un proprio sistema esperto in operazione e stava studiando sistemi più avanzati. Nel 1981 in Giappone venne annunciato il progetto Fifth Generation, un piano di dieci anni con l’intento di costruire sistemi intelligenti basati su Prolog. In risposta, gli Stati Uniti d’America crearono la Microelectronics and Computer Technology Corporation (MCC), come consorzio di ricerca al fine di garantire la competitività a livello nazionale. In Inghilterra, il rapporto Alvey recuperò i fondi tagliati dal rapporto Lighthill, che nel 1973 portò il governo britannico alla decisione di interrompere il supporto verso la ricerca nell'ambito dell'intelligenza artificiale. Questi progetti però non raggiunsero gli scopi previsti. L’industria dell’intelligenza artificiale raggiunse nel 1988 una cifra dell'ordine di miliardi di dollari, includendo centinaia di aziende che stavano creando sistemi esperti, robot e software e hardware specializzati in questi settori.

Il ritorno delle reti neurali (1986-)
A metà degli anni ottanta dello scorso secolo fu reinventato l’algoritmo di apprendimento per reti neurali chiamato back-propagation, inizialmente ideato nel 1969 da Bryson e Ho. L’algoritmo fu applicato a molti problemi relativi all’apprendimento, inerenti sia al lato dell’informatica sia a quello della psicologia. I cosiddetti modelli connessionisti per la realizzazione di sistemi intelligenti furono visti come alternative ai modelli simbolici ideati da Newell e Simon, da McCarthy e dai loro collaboratori. Tali modelli cercarono di dare risposta a quelle domande alle quali i precedenti modelli non erano riusciti, ma in parte fallirono anch’essi. Di conseguenza, i modelli basati sull’approccio simbolico e quelli con un approccio connessionista furono visti come complementari.

L’intelligenza artificiale al giorno d’oggi (1986-)
Al giorno d’oggi i sistemi intelligenti sono presenti in ogni campo, anche nelle attività quotidiane e primeggiano nei giochi, come teorizzato anni prima dagli esponenti dell’intelligenza artificiale. Vi sono programmi che sono stati in grado di confrontarsi con campioni di scacchi, quali Deep Blue; altri che sono stati impiegati nelle missioni spaziali, come nel 1998 quando la NASA utilizzò un programma chiamato Remote Agent in grado di gestire le attività relative a un sistema spaziale; alcune auto sono oggi dotate di un sistema in grado di guidarle senza l’uso di un conducente umano, quindi in maniera del tutto autonoma. Nell’ambito di scenari più quotidiani si pensi, invece, ai termostati per il riscaldamento e l’aria condizionata in grado di anticipare il cambio di temperatura, gestire i bisogni degli inquilini e di interagire con altri dispositivi.

Principi di Asilomar
Nel 2017 a seguito del convegno di esperti mondiali di intelligenza artificiale promosso dal Future of Live Institute ,è stato redatto con ampissimo consenso un vademecum con 23 principi per affrontare le problematiche etiche,sociali,culturali,militari,dell'IA ,il documento è stato sottoscritto subito da oltre 800 esperti ed in seguito da altri migliaia[9][10].

I Principi di Asilomar
1. OBIETTIVO DELLA RICERCA: Lo scopo della ricerca sull’AI deve creare un’intelligenza della quale beneficiare e non un’intelligenza senza uno scopo. 2. FINANZIAMENTO DELLA RICERCA: Gli investimenti in materia di AI devono essere accompagnati dai finanziamenti per la ricerca al fine di assicurare un uso da cui trarre beneficio, includendo questioni spinose in materia di informatica, economia, legge, etica e studi economici come: – Come possiamo rendere altamente solidi i sistemi di AI del futuro in modo che questi non siano malfunzionanti oppure oggetto di hacking? – Come possiamo accrescere la nostra prosperità attraverso l’automazione pur mantenendo le risorse e gli scopi delle persone? – Come possiamo aggiornare i nostri sistemi legali in modo da renderli più corretti ed efficienti al fine di andare di pari passo con l’AI e riuscendo a gestire i rischi ad essa associati? – A quale tipo di valori dovremmo allineare l’AI e quali status legali ed etici dovremmo attribuirle? 3. COLLEGAMENTI TRA POLITICA E SCIENZA: Ci dovrebbe essere uno scambio costruttivo e sano tra i ricercatori di intelligenza artificiale e i politici. 4. CULTURA DELLA RICERCA: Una cultura di cooperazione, fiducia e trasparenza dovrebbe costituire la base di chi si occupa di ricerca e sviluppo dell’AI. 5. EVITARE LE CORSE: I team che si occupano dello sviluppo di sistemi AI devono cooperare attivamente per evitare scorciatoie a discapito dei sistemi di sicurezza. 6. SICUREZZA: I sistemi di AI dovrebbero essere sicuri e protetti nel corso di tutta la durata del loro ciclo di vita e verificabili nella loro fattibilità. 7. TRASPARENZA IN CASO DI INSUCCESSO: nel momento in cui un sistema di AI causasse un danno sarebbe possibile scoprirne le cause. 8. TRASPARENZA DEI GIUDIZI: Qualsiasi coinvolgimento da parte di un sistema decisionale autonomo in materia di giustizia dovrebbe fornire spiegazioni soddisfacenti e verificabili da parte delle autorità umane competenti. 9. RESPONSABILITÀ: I progettisti e i costruttori dei sistemi avanzati di AI sono parte attiva nelle implicazioni morali del loro uso e abuso, ma anche delle azioni e hanno la responsabilità e l’opportunità di plasmare tali implicazioni. 10. ALLINEAMENTO DEI VALORI: I sistemi di AI altamente autonomi dovrebbero essere progettati affinché i loro scopi e comportamenti possano garantire di essere allineati con i valori umani ad ogni operazione. 11. VALORI UMANI: i sistemi di AI devono essere progettati e gestiti in modo da essere compatibili con gli ideali di dignità umana, i diritti, le libertà e la diversità culturale. 12. PRIVACY PERSONALE: Le persone dovrebbero avere il diritto di accedere, gestire e controllare i dati che generano e, di pari passo, dare ai sistemi AI la possibilità di analizzare e utilizzare tali dati. 13. LIBERTÀ E PRIVACY: L’applicazione dell’AI ai dati personali non deve limitare irragionevolmente l’idea di libertà delle persone, sia reale che percepita. 14. BENEFICI CONDIVISI: Le tecnologie AI dovrebbero beneficiare e potenziale più persone possibili. 15. PROSPERITÀ CONDIVISA: La prosperità economica creata dall’AI dovrebbe essere condivisa in modo ampio, per dare beneficio a tutta l’umanità. 16. CONTROLLO UMANO: Gli esseri umani dovrebbero scegliere come e se delegare le decisioni ai sistemi di AI per raggiungere i propri obiettivi umani. 17. NON-SOVVERSIONE: Il potere conferito dal controllo dei sistemi di AI altamente avanzati dovrebbe rispettare e migliorare, piuttosto che sovvertire, i processi sociali e civili tra il benessere della società. 18. CORSA ALLE ARMI AI: Una corsa agli armamenti di armi letali autonome dovrebbe essere evitata. 19. GRADI DI PRECAUZIONE: In caso di mancato consenso, dovremmo evitare forti ipotesi riguardanti i limiti massimi sulle future capacità dell’AI. 20. IMPORTANZA: L’AI avanzata potrebbe rappresentare un cambiamento profondo nella storia della vita sulla Terra e dovrebbe essere pianificata e gestita con cura e risorse commisurate. 21. RISCHI: I rischi associati ai sistemi AI, in particolare, i rischi catastrofici o esistenziali, devono essere oggetto di pianificazione e mitigazione degli sforzi, affinché siano commisurati con il loro impatto atteso. 22. MIGLIORAMENTO PERSONALE RICORSIVO: I sistemi di AI progettati per auto-migliorarsi o auto-replicarsi ricorrentemente in modo che possano portare ad un rapido aumento della qualità o delle quantità, devono essere oggetto di misure di sicurezza e di controllo severe. 23. BENE COMUNE: La Super-intelligenza dovrebbe essere sviluppata esclusivamente al servizio di ideali etici ampiamente condivisi e a beneficio di tutta l’umanità, anziché di un solo paese o organizzazione.

Ricerca
Il problema complesso dello sviluppare sistemi che esibiscono comportamenti intelligenti è stato affrontato operando una scomposizione in sotto-problemi, ognuno con uno specifico ambito di ricerca. Ogni sotto-problema consiste nello studiare particolari abilità e proprietà che caratterizzano il sistema intelligente.

Relativamente all'ambito di applicazione di un determinato sistema intelligente questo presenterà soluzioni più o meno sofisticate per ogni sotto-problema.

Intelligenza artificiale forte e debole
Una primaria distinzione in seno alla ricerca nel campo dell'intelligenza artificiale è quella di intelligenza artificiale debole e intelligenza artificiale forte a secondo che vengano riprodotte solo alcune o tutte le funzionalità della mente umana.

